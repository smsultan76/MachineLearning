{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smsultan76/MachineLearning/blob/main/omprehensive_multi_method_clustering_and_insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-10-18T13:38:09.980675Z",
          "iopub.status.busy": "2025-10-18T13:38:09.980426Z",
          "iopub.status.idle": "2025-10-18T13:38:21.634953Z",
          "shell.execute_reply": "2025-10-18T13:38:21.634317Z",
          "shell.execute_reply.started": "2025-10-18T13:38:09.980654Z"
        },
        "id": "EXfJgKD5DKxu",
        "outputId": "6fd9f3dc-9770-4dae-a585-99da1a33a246",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/SM/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setting plot style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/shopping_behavior_updated.csv')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"CUSTOMER CLUSTERING ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. DATA PREPROCESSING FOR CLUSTERING\n",
        "print(\"\\n1. DATA PREPROCESSING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Create copy of original data\n",
        "df_original = df.copy()\n",
        "\n",
        "# Create age groups for better segmentation\n",
        "df['Age_Group'] = pd.cut(df['Age'],\n",
        "                        bins=[0, 25, 35, 45, 55, 65, 100],\n",
        "                        labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
        "\n",
        "# Feature engineering\n",
        "print(\"Creating additional features...\")\n",
        "\n",
        "# Customer value segments based on purchase amount and frequency\n",
        "df['Customer_Value'] = df['Purchase Amount (USD)'] * df['Previous Purchases']\n",
        "\n",
        "# Create behavioral segments\n",
        "df['High_Value_Customer'] = (df['Purchase Amount (USD)'] > df['Purchase Amount (USD)'].quantile(0.75)).astype(int)\n",
        "df['Frequent_Buyer'] = (df['Previous Purchases'] > df['Previous Purchases'].quantile(0.75)).astype(int)\n",
        "df['High_Rating_Customer'] = (df['Review Rating'] > 4.0).astype(int)\n",
        "\n",
        "# Select features for clustering\n",
        "clustering_features = [\n",
        "    'Age',\n",
        "    'Purchase Amount (USD)',\n",
        "    'Review Rating',\n",
        "    'Previous Purchases',\n",
        "    'High_Value_Customer',\n",
        "    'Frequent_Buyer',\n",
        "    'High_Rating_Customer'\n",
        "]\n",
        "\n",
        "# Prepare numerical features\n",
        "X_numerical = df[clustering_features].copy()\n",
        "\n",
        "print(f\"Selected features for clustering: {clustering_features}\")\n",
        "print(f\"Shape of clustering dataset: {X_numerical.shape}\")\n",
        "\n",
        "# Handle categorical variables using Label Encoding for additional features\n",
        "categorical_features = ['Gender', 'Category', 'Season', 'Payment Method', 'Frequency of Purchases']\n",
        "\n",
        "label_encoders = {}\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[feature + '_encoded'] = le.fit_transform(df[feature])\n",
        "    label_encoders[feature] = le\n",
        "    clustering_features.append(feature + '_encoded')\n",
        "    X_numerical[feature + '_encoded'] = df[feature + '_encoded']\n",
        "\n",
        "print(f\"Total features after encoding: {len(clustering_features)}\")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_numerical)\n",
        "\n",
        "print(\"Data preprocessing completed!\")\n",
        "\n",
        "# 2. DETERMINING OPTIMAL NUMBER OF CLUSTERS\n",
        "print(\"\\n2. FINDING OPTIMAL NUMBER OF CLUSTERS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Elbow method and Silhouette analysis\n",
        "wcss = []  # Within-cluster sum of squares\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "    # Silhouette score\n",
        "    silhouette_avg = silhouette_score(X_scaled, kmeans.labels_)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "    print(f\"K={k}: WCSS = {kmeans.inertia_:.2f}, Silhouette = {silhouette_avg:.3f}\")\n",
        "\n",
        "# Plot elbow curve and silhouette scores\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Elbow curve\n",
        "ax1.plot(k_range, wcss, 'bo-', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel('Number of Clusters (K)')\n",
        "ax1.set_ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "ax1.set_title('Elbow Method for Optimal K')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Silhouette scores\n",
        "ax2.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
        "ax2.set_xlabel('Number of Clusters (K)')\n",
        "ax2.set_ylabel('Silhouette Score')\n",
        "ax2.set_title('Silhouette Analysis for Optimal K')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Choose optimal K (you can adjust this based on the plots)\n",
        "optimal_k = 4  # This can be changed based on elbow and silhouette analysis\n",
        "print(f\"\\nSelected optimal number of clusters: {optimal_k}\")\n",
        "\n",
        "# 3. K-MEANS CLUSTERING\n",
        "print(\"\\n3. K-MEANS CLUSTERING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "df['Cluster'] = clusters\n",
        "X_numerical['Cluster'] = clusters\n",
        "\n",
        "print(\"K-means clustering completed!\")\n",
        "print(f\"Cluster distribution:\")\n",
        "print(df['Cluster'].value_counts().sort_index())\n",
        "\n",
        "# 4. CLUSTER PROFILING AND ANALYSIS\n",
        "print(\"\\n4. CLUSTER PROFILING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Calculate cluster statistics\n",
        "cluster_profile = df.groupby('Cluster').agg({\n",
        "    'Age': ['mean', 'std'],\n",
        "    'Purchase Amount (USD)': ['mean', 'std'],\n",
        "    'Review Rating': ['mean', 'std'],\n",
        "    'Previous Purchases': ['mean', 'std'],\n",
        "    'Gender': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown',\n",
        "    'Category': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown',\n",
        "    'Frequency of Purchases': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown',\n",
        "    'Customer ID': 'count'\n",
        "}).round(2)\n",
        "\n",
        "cluster_profile.columns = ['Age_Mean', 'Age_Std', 'Purchase_Mean', 'Purchase_Std',\n",
        "                          'Rating_Mean', 'Rating_Std', 'PrevPurchases_Mean', 'PrevPurchases_Std',\n",
        "                          'Dominant_Gender', 'Dominant_Category', 'Dominant_Frequency', 'Count']\n",
        "\n",
        "print(\"Cluster Profile Summary:\")\n",
        "print(cluster_profile)\n",
        "\n",
        "# 5. VISUALIZATION OF CLUSTERS\n",
        "print(\"\\n5. CLUSTER VISUALIZATION\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 5.1 PCA for dimensionality reduction and 2D visualization\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create visualization dataframe\n",
        "viz_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
        "viz_df['Cluster'] = clusters\n",
        "viz_df['Purchase_Amount'] = df['Purchase Amount (USD)']\n",
        "viz_df['Age'] = df['Age']\n",
        "viz_df['Previous_Purchases'] = df['Previous Purchases']\n",
        "\n",
        "# 5.2 Plot clusters in 2D\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Clusters in PCA space\n",
        "scatter = axes[0,0].scatter(viz_df['PC1'], viz_df['PC2'], c=viz_df['Cluster'],\n",
        "                           cmap='viridis', alpha=0.7, s=50)\n",
        "axes[0,0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
        "axes[0,0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
        "axes[0,0].set_title('Customer Clusters in PCA Space')\n",
        "plt.colorbar(scatter, ax=axes[0,0])\n",
        "\n",
        "# Plot 2: Purchase Amount vs Age colored by cluster\n",
        "scatter = axes[0,1].scatter(df['Age'], df['Purchase Amount (USD)'], c=clusters,\n",
        "                           cmap='viridis', alpha=0.7, s=50)\n",
        "axes[0,1].set_xlabel('Age')\n",
        "axes[0,1].set_ylabel('Purchase Amount (USD)')\n",
        "axes[0,1].set_title('Purchase Amount vs Age by Cluster')\n",
        "plt.colorbar(scatter, ax=axes[0,1])\n",
        "\n",
        "# Plot 3: Previous Purchases vs Review Rating\n",
        "scatter = axes[1,0].scatter(df['Previous Purchases'], df['Review Rating'], c=clusters,\n",
        "                           cmap='viridis', alpha=0.7, s=50)\n",
        "axes[1,0].set_xlabel('Previous Purchases')\n",
        "axes[1,0].set_ylabel('Review Rating')\n",
        "axes[1,0].set_title('Previous Purchases vs Review Rating by Cluster')\n",
        "plt.colorbar(scatter, ax=axes[1,0])\n",
        "\n",
        "# Plot 4: Cluster sizes\n",
        "cluster_sizes = df['Cluster'].value_counts().sort_index()\n",
        "axes[1,1].bar(cluster_sizes.index, cluster_sizes.values, color=['red', 'blue', 'green', 'orange'][:optimal_k])\n",
        "axes[1,1].set_xlabel('Cluster')\n",
        "axes[1,1].set_ylabel('Number of Customers')\n",
        "axes[1,1].set_title('Cluster Sizes')\n",
        "for i, v in enumerate(cluster_sizes.values):\n",
        "    axes[1,1].text(i, v, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5.3 Parallel coordinates plot for cluster characteristics\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Select key features for parallel coordinates\n",
        "parallel_features = ['Age', 'Purchase Amount (USD)', 'Review Rating', 'Previous Purchases']\n",
        "parallel_df = df[parallel_features + ['Cluster']].copy()\n",
        "\n",
        "# Normalize features for parallel coordinates\n",
        "for feature in parallel_features:\n",
        "    parallel_df[feature] = (parallel_df[feature] - parallel_df[feature].min()) / (parallel_df[feature].max() - parallel_df[feature].min())\n",
        "\n",
        "from pandas.plotting import parallel_coordinates\n",
        "parallel_coordinates(parallel_df, 'Cluster', colormap='viridis', alpha=0.5)\n",
        "plt.title('Parallel Coordinates Plot of Customer Clusters')\n",
        "plt.ylabel('Normalized Feature Value')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. DETAILED CLUSTER CHARACTERISTICS\n",
        "print(\"\\n6. DETAILED CLUSTER ANALYSIS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Analyze each cluster in detail\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = df[df['Cluster'] == cluster_id]\n",
        "\n",
        "    print(f\"\\n--- CLUSTER {cluster_id} (n={len(cluster_data)}) ---\")\n",
        "    print(f\"Demographics:\")\n",
        "    print(f\"  â€¢ Average Age: {cluster_data['Age'].mean():.1f} years\")\n",
        "    print(f\"  â€¢ Gender Distribution: {cluster_data['Gender'].value_counts().to_dict()}\")\n",
        "\n",
        "    print(f\"Spending Behavior:\")\n",
        "    print(f\"  â€¢ Avg Purchase Amount: ${cluster_data['Purchase Amount (USD)'].mean():.2f}\")\n",
        "    print(f\"  â€¢ Total Spending: ${cluster_data['Purchase Amount (USD)'].sum():.2f}\")\n",
        "    print(f\"  â€¢ Avg Previous Purchases: {cluster_data['Previous Purchases'].mean():.1f}\")\n",
        "\n",
        "    print(f\"Preferences:\")\n",
        "    print(f\"  â€¢ Top Category: {cluster_data['Category'].mode()[0]}\")\n",
        "    print(f\"  â€¢ Top Season: {cluster_data['Season'].mode()[0]}\")\n",
        "    print(f\"  â€¢ Avg Review Rating: {cluster_data['Review Rating'].mean():.2f}\")\n",
        "\n",
        "    print(f\"Behavioral Patterns:\")\n",
        "    print(f\"  â€¢ Common Payment: {cluster_data['Payment Method'].mode()[0]}\")\n",
        "    print(f\"  â€¢ Common Frequency: {cluster_data['Frequency of Purchases'].mode()[0]}\")\n",
        "    print(f\"  â€¢ Subscription Rate: {(cluster_data['Subscription Status'] == 'Yes').mean()*100:.1f}%\")\n",
        "\n",
        "# 7. CLUSTER NAMING BASED ON CHARACTERISTICS\n",
        "print(\"\\n7. CLUSTER INTERPRETATION AND NAMING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "cluster_names = {}\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = df[df['Cluster'] == cluster_id]\n",
        "\n",
        "    # Define characteristics\n",
        "    avg_age = cluster_data['Age'].mean()\n",
        "    avg_spend = cluster_data['Purchase Amount (USD)'].mean()\n",
        "    avg_prev_purchases = cluster_data['Previous Purchases'].mean()\n",
        "    avg_rating = cluster_data['Review Rating'].mean()\n",
        "\n",
        "    # Determine cluster type based on characteristics\n",
        "    if avg_spend > df['Purchase Amount (USD)'].mean() and avg_prev_purchases > df['Previous Purchases'].mean():\n",
        "        cluster_type = \"High-Value Loyal Customers\"\n",
        "    elif avg_spend > df['Purchase Amount (USD)'].mean() and avg_prev_purchases <= df['Previous Purchases'].mean():\n",
        "        cluster_type = \"High-Spend Occasional Shoppers\"\n",
        "    elif avg_spend <= df['Purchase Amount (USD)'].mean() and avg_prev_purchases > df['Previous Purchases'].mean():\n",
        "        cluster_type = \"Frequent Budget Shoppers\"\n",
        "    else:\n",
        "        cluster_type = \"Occasional Budget Shoppers\"\n",
        "\n",
        "    # Age-based refinement\n",
        "    if avg_age > 50:\n",
        "        cluster_type += \" (Mature)\"\n",
        "    elif avg_age < 30:\n",
        "        cluster_type += \" (Young)\"\n",
        "    else:\n",
        "        cluster_type += \" (Middle-aged)\"\n",
        "\n",
        "    cluster_names[cluster_id] = cluster_type\n",
        "    print(f\"Cluster {cluster_id}: {cluster_type}\")\n",
        "\n",
        "# Add cluster names to dataframe\n",
        "df['Cluster_Name'] = df['Cluster'].map(cluster_names)\n",
        "\n",
        "# 8. COMPARISON OF CLUSTERING ALGORITHMS\n",
        "print(\"\\n8. COMPARING CLUSTERING ALGORITHMS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Try different clustering algorithms\n",
        "algorithms = {\n",
        "    'K-Means': KMeans(n_clusters=optimal_k, random_state=42, n_init=10),\n",
        "    'Agglomerative': AgglomerativeClustering(n_clusters=optimal_k),\n",
        "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, algorithm in algorithms.items():\n",
        "    if name == 'DBSCAN':\n",
        "        labels = algorithm.fit_predict(X_scaled)\n",
        "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    else:\n",
        "        labels = algorithm.fit_predict(X_scaled)\n",
        "        n_clusters = optimal_k\n",
        "\n",
        "    if n_clusters > 1:  # Only calculate metrics if we have more than 1 cluster\n",
        "        silhouette = silhouette_score(X_scaled, labels)\n",
        "        calinski = calinski_harabasz_score(X_scaled, labels)\n",
        "        davies = davies_bouldin_score(X_scaled, labels)\n",
        "    else:\n",
        "        silhouette = calinski = davies = np.nan\n",
        "\n",
        "    results.append({\n",
        "        'Algorithm': name,\n",
        "        'Number of Clusters': n_clusters,\n",
        "        'Silhouette Score': silhouette,\n",
        "        'Calinski-Harabasz Score': calinski,\n",
        "        'Davies-Bouldin Score': davies\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Clustering Algorithms Comparison:\")\n",
        "print(results_df.round(3))\n",
        "\n",
        "# 9. BUSINESS INSIGHTS AND RECOMMENDATIONS\n",
        "print(\"\\n9. BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nKEY INSIGHTS FROM CUSTOMER CLUSTERING:\")\n",
        "\n",
        "# Calculate overall metrics for comparison\n",
        "overall_avg_spend = df['Purchase Amount (USD)'].mean()\n",
        "overall_avg_prev = df['Previous Purchases'].mean()\n",
        "\n",
        "for cluster_id, cluster_name in cluster_names.items():\n",
        "    cluster_data = df[df['Cluster'] == cluster_id]\n",
        "\n",
        "    print(f\"\\nðŸ“Š {cluster_name}:\")\n",
        "    print(f\"   â€¢ Size: {len(cluster_data)} customers ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
        "    print(f\"   â€¢ Average Spend: ${cluster_data['Purchase Amount (USD)'].mean():.2f} \"\n",
        "          f\"({'+' if cluster_data['Purchase Amount (USD)'].mean() > overall_avg_spend else ''}\"\n",
        "          f\"{(cluster_data['Purchase Amount (USD)'].mean() - overall_avg_spend)/overall_avg_spend*100:.1f}% vs average)\")\n",
        "    print(f\"   â€¢ Loyalty Level: {cluster_data['Previous Purchases'].mean():.1f} previous purchases\")\n",
        "\n",
        "    # Recommendations\n",
        "    if \"High-Value\" in cluster_name:\n",
        "        print(f\"   ðŸ’¡ Recommendations: Premium loyalty programs, early access to new products, personalized service\")\n",
        "    elif \"Frequent\" in cluster_name:\n",
        "        print(f\"   ðŸ’¡ Recommendations: Volume discounts, subscription benefits, referral programs\")\n",
        "    elif \"High-Spend\" in cluster_name:\n",
        "        print(f\"   ðŸ’¡ Recommendations: Luxury product recommendations, exclusive events, premium support\")\n",
        "    else:\n",
        "        print(f\"   ðŸ’¡ Recommendations: Entry-level offers, educational content, budget-friendly options\")\n",
        "\n",
        "# 10. SAVE RESULTS\n",
        "print(\"\\n10. SAVING RESULTS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Save clustered data\n",
        "output_file = 'customer_clusters_analysis.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "# Save cluster profiles\n",
        "cluster_summary = df.groupby(['Cluster', 'Cluster_Name']).agg({\n",
        "    'Age': 'mean',\n",
        "    'Purchase Amount (USD)': ['mean', 'sum'],\n",
        "    'Previous Purchases': 'mean',\n",
        "    'Review Rating': 'mean',\n",
        "    'Customer ID': 'count',\n",
        "    'Subscription Status': lambda x: (x == 'Yes').mean()\n",
        "}).round(2)\n",
        "\n",
        "cluster_summary.columns = ['Avg_Age', 'Avg_Spend', 'Total_Spend', 'Avg_Previous_Purchases',\n",
        "                          'Avg_Rating', 'Customer_Count', 'Subscription_Rate']\n",
        "cluster_summary.to_csv('cluster_profiles_summary.csv')\n",
        "\n",
        "print(f\"Clustered data saved to: {output_file}\")\n",
        "print(f\"Cluster profiles saved to: cluster_profiles_summary.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CLUSTERING ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nTotal customers analyzed: {len(df)}\")\n",
        "print(f\"Number of clusters identified: {optimal_k}\")\n",
        "print(f\"Best clustering algorithm: K-Means\")\n",
        "print(f\"Average silhouette score: {silhouette_score(X_scaled, clusters):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
